import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from collections import Counter, defaultdict
import re
import time
import platform
import os

# ë¼ì´ë¸Œ í¬ë¡¤ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬
from selenium import webdriver
from selenium.webdriver.common.by import By
# ### [ìˆ˜ì •/Modified] Service ëª¨ë“ˆ ì¶”ê°€ ###
from selenium.webdriver.chrome.service import Service 
import chromedriver_autoinstaller

# ---------------------------------------------------------
# 1. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ---------------------------------------------------------
st.set_page_config(
    page_title="Global Research Trend Tracker",
    page_icon="ğŸ§¬",
    layout="wide"
)

# í•œê¸€ í°íŠ¸ ì„¤ì •
if platform.system() == 'Darwin': # Mac
    plt.rc('font', family='AppleGothic')
else: # Windows
    plt.rc('font', family='Malgun Gothic')
plt.rc('axes', unicode_minus=False)

# ---------------------------------------------------------
# 2. ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™”
# ---------------------------------------------------------
if 'user_excludes' not in st.session_state:
    st.session_state.user_excludes = [
        'analysis', 'study', 'method', 'using', 'based', 'data', 'journal',
        'and', 'the', 'for', 'from', 'with', 'between', 'during', 'review',
        'research', 'results', 'model', 'approach', 'effect', 'response',
        'potential', 'application', 'development'
    ]

if 'crawled_df' not in st.session_state:
    st.session_state.crawled_df = None

if 'current_search_keyword' not in st.session_state:
    st.session_state.current_search_keyword = ""

# ---------------------------------------------------------
# 3. í•¨ìˆ˜ ì •ì˜
# ---------------------------------------------------------
def get_saved_files():
    files = [f.replace('_data.csv', '') for f in os.listdir('.') if f.endswith('_data.csv')]
    return sorted(files)

def load_csv_data(crop_name):
    file_path = f"{crop_name}_data.csv"
    try:
        df = pd.read_csv(file_path)
        if 'Views' not in df.columns:
            df['Views'] = 1 
        return df
    except FileNotFoundError:
        return None

def crawl_live_data(keyword):
    driver = None
    status_placeholder = st.empty()

    try:
        # ### [ìˆ˜ì •/Modified] ë“œë¼ì´ë²„ ì„¤ì • ë¡œì§ ì „ì²´ ë³€ê²½ ###
        options = webdriver.ChromeOptions()
        
        # 1. Headless ëª¨ë“œ í™œì„±í™” (ì„œë²„ í™˜ê²½ í•„ìˆ˜)
        options.add_argument("--headless") 
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-gpu")
        
        # 2. User-Agent ì„¤ì • (ë´‡ íƒì§€ ìš°íšŒ)
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option("useAutomationExtension", False)
        options.add_argument("--window-size=1920,1080")

        # 3. ìš´ì˜ì²´ì œ(OS)ì— ë”°ë¥¸ ë“œë¼ì´ë²„ ê²½ë¡œ ì„¤ì •
        if platform.system() == 'Linux':
            # Streamlit Cloud (Linux) í™˜ê²½
            # packages.txtì— ì˜í•´ ì„¤ì¹˜ëœ ê²½ë¡œë¥¼ ì§€ì •
            options.binary_location = "/usr/bin/chromium"
            service = Service(executable_path="/usr/bin/chromedriver")
            driver = webdriver.Chrome(service=service, options=options)
            print("âœ… Linux í™˜ê²½(Streamlit Cloud) ê°ì§€: ì‹œìŠ¤í…œ ë“œë¼ì´ë²„ ì‚¬ìš©")
        else:
            # ë¡œì»¬(Windows/Mac) í™˜ê²½
            # ê¸°ì¡´ì²˜ëŸ¼ autoinstaller ì‚¬ìš©
            chromedriver_autoinstaller.install()
            driver = webdriver.Chrome(options=options)
            print("âœ… ë¡œì»¬ í™˜ê²½ ê°ì§€: Autoinstaller ë“œë¼ì´ë²„ ì‚¬ìš©")
        
        # ---------------------------------------------------------
        
        url = f"https://www.mdpi.com/search?q={keyword}" 
        driver.get(url)
        
        msg = f"â³ í˜ì´ì§€ ë¡œë”© ì¤‘... '{keyword}' ê²€ìƒ‰ (ì•½ 5ì´ˆ ëŒ€ê¸°)"
        print(msg) 
        status_placeholder.info(msg)
        time.sleep(5) 
        
        is_new_version = False
        try:
            if "new version of our website" in driver.page_source.lower():
                is_new_version = True
                print("ğŸš¨ ê°ì§€ë¨: ì‚¬ì´íŠ¸ê°€ 'New Version'ì…ë‹ˆë‹¤.")
        except:
            pass

        articles = driver.find_elements(By.CLASS_NAME, "generic-item")
        print(f"DEBUG: 'generic-item' ê°œìˆ˜: {len(articles)}")

        if is_new_version or len(articles) == 0:
            # Headless ëª¨ë“œì—ì„œëŠ” 'í´ë¦­' ìœ ë„ê°€ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ, ë°”ë¡œ ë‹¤ë¥¸ íƒœê·¸ë¥¼ ì°¾ê±°ë‚˜ ëŒ€ê¸°ë§Œ ìˆ˜í–‰
            print("ğŸš¨ êµ¬ì¡° ë³€ê²½ ê°ì§€ ë˜ëŠ” ë¡œë”© ì§€ì—°. ì¶”ê°€ ëŒ€ê¸° ë° íƒœê·¸ íƒìƒ‰ ì‹œë„.")
            
            for i in range(5, 0, -1):
                check_articles = driver.find_elements(By.CLASS_NAME, "generic-item")
                if len(check_articles) > 0:
                    status_placeholder.success("âœ… ë°ì´í„° ë¡œë”© í™•ì¸!")
                    articles = check_articles
                    break 
                time.sleep(1)
            
            if len(articles) == 0:
                print("DEBUG: êµ¬ ë²„ì „ ê°ì§€ ì‹¤íŒ¨. ì‹ ê·œ êµ¬ì¡°(article-item) íƒìƒ‰ ì‹œë„.")
                articles = driver.find_elements(By.CLASS_NAME, "article-item")

        print(f"ìµœì¢… ë°œê²¬ëœ ìš”ì†Œ ìˆ˜: {len(articles)}")
        
        data = []
        garbage_keywords = ["Sign in", "Update Search", "Publication Date", "Show export options", "Unknown", "Subscribe"]

        for art in articles:
            try:
                try:
                    title_elem = art.find_element(By.CLASS_NAME, "title-link")
                except:
                    try:
                        title_elem = art.find_element(By.TAG_NAME, "a")
                    except:
                        continue
                
                title = title_elem.text.strip()
                
                if not title or len(title) < 20:
                    continue
                if any(bad_word in title for bad_word in garbage_keywords):
                    continue

                try:
                    authors = art.find_element(By.CLASS_NAME, "authors").text
                except:
                    authors = "Unknown"
                
                if not authors or authors == "Unknown":
                    continue

                full_text = art.text
                view_match = re.search(r"(?:Viewed by|Views)[:\s]*([\d,]+)", full_text)
                if view_match:
                    views = int(view_match.group(1).replace(",", ""))
                else:
                    views = 1 

                data.append([keyword, title, authors, views])
            except Exception as e:
                continue
        
        status_placeholder.empty()
        
    except Exception as e:
        err_msg = f"í¬ë¡¤ë§ ì‹œìŠ¤í…œ ì—ëŸ¬: {e}"
        print(err_msg)
        st.error(err_msg)
        return pd.DataFrame()
    finally:
        if driver:
            try:
                driver.quit()
            except:
                pass
        
    if data:
        return pd.DataFrame(data, columns=['Keyword', 'Title', 'Authors', 'Views'])
    else:
        return pd.DataFrame()

# ---------------------------------------------------------
# 4. ì‚¬ì´ë“œë°” UI
# ---------------------------------------------------------
st.sidebar.header("ğŸ” ë¶„ì„ ì»¨íŠ¸ë¡¤ íŒ¨ë„")

data_source = st.sidebar.radio(
    "ë°ì´í„° ì†ŒìŠ¤",
    ("ğŸ“‚ ì €ì¥ëœ íŒŒì¼(CSV)", "ğŸŒ ì‹¤ì‹œê°„ ê²€ìƒ‰(Live)")
)

if data_source == "ğŸ“‚ ì €ì¥ëœ íŒŒì¼(CSV)":
    saved_files = get_saved_files()
    if saved_files:
        crop_option = st.sidebar.selectbox("ì €ì¥ëœ ë°ì´í„° ì„ íƒ", saved_files)
        if st.session_state.current_search_keyword != crop_option:
            df = load_csv_data(crop_option)
            st.session_state.crawled_df = df
            st.session_state.current_search_keyword = crop_option
    else:
        st.sidebar.warning("ì €ì¥ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

else: # ë¼ì´ë¸Œ ëª¨ë“œ
    live_keyword = st.sidebar.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œ", "Smart Farm")
    
    if st.sidebar.button("ğŸš€ ê²€ìƒ‰ ì‹œì‘"):
        st.session_state.crawled_df = None 
        
        with st.spinner(f"MDPIì—ì„œ '{live_keyword}' ê´€ë ¨ ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤..."):
            df = crawl_live_data(live_keyword)
            if not df.empty:
                st.session_state.crawled_df = df
                st.session_state.current_search_keyword = live_keyword
                st.success(f"ìˆ˜ì§‘ ì™„ë£Œ! ({len(df)}ê±´)")
            else:
                st.error("ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ìˆ˜ë™ ì „í™˜ ì‹¤íŒ¨ ë˜ëŠ” ë°ì´í„° ì—†ìŒ)")

    if st.session_state.crawled_df is not None and not st.session_state.crawled_df.empty:
        
        # 1. ë°ì´í„°í”„ë ˆì„ì„ CSV ë¬¸ìì—´ë¡œ ë³€í™˜ (í•œê¸€ ê¹¨ì§ ë°©ì§€ utf-8-sig)
        csv_data = st.session_state.crawled_df.to_csv(index=False).encode('utf-8-sig')

        # 2. ì €ì¥í•˜ê¸° ë²„íŠ¼ ëŒ€ì‹  'ë‹¤ìš´ë¡œë“œ ë²„íŠ¼' ìƒì„±
        filename = f"{st.session_state.current_search_keyword}_data.csv"
        
        st.sidebar.download_button(
            label="ğŸ’¾ ê²°ê³¼ ì»´í“¨í„°ë¡œ ë‹¤ìš´ë¡œë“œ",
            data=csv_data,
            file_name=filename,
            mime='text/csv'
        )

st.sidebar.markdown("---")

# ì œì™¸ ë‹¨ì–´ ê´€ë¦¬
st.sidebar.subheader("ğŸš« ì œì™¸ ë‹¨ì–´ ê´€ë¦¬")
col_add1, col_add2 = st.sidebar.columns([3, 1])
with col_add1:
    new_stopword = st.text_input("ë‹¨ì–´ ì¶”ê°€ (ì‰¼í‘œë¡œ êµ¬ë¶„ ê°€ëŠ¥)", placeholder="ì˜ˆ: review, analysis, data", label_visibility="collapsed")
with col_add2:
    if st.button("ì¶”ê°€"):
        if new_stopword:
            new_words = [word.strip().lower() for word in new_stopword.split(',')]
            added_count = 0
            for word in new_words:
                if word and word not in st.session_state.user_excludes:
                    st.session_state.user_excludes.append(word)
                    added_count += 1
            
            if added_count > 0:
                st.rerun()

if st.sidebar.button("ğŸ”„ ì œì™¸ ë‹¨ì–´ ì´ˆê¸°í™”"):
    st.session_state.user_excludes = [
        'analysis', 'study', 'method', 'using', 'based', 'data', 'journal',
        'and', 'the', 'for', 'from', 'with', 'between', 'during', 'review',
        'research', 'results', 'model', 'approach', 'effect', 'response',
        'potential', 'application', 'development'
    ]
    st.rerun()

current_excludes = st.sidebar.multiselect(
    "í˜„ì¬ ì œì™¸ëœ ë‹¨ì–´ë“¤ (x ëˆŒëŸ¬ ì‚­ì œ)",
    options=st.session_state.user_excludes,
    default=st.session_state.user_excludes
)

if set(current_excludes) != set(st.session_state.user_excludes):
    st.session_state.user_excludes = current_excludes
    st.rerun()

# ---------------------------------------------------------
# 5. ë©”ì¸ ëŒ€ì‹œë³´ë“œ
# ---------------------------------------------------------
final_df = st.session_state.crawled_df
keyword_display = st.session_state.current_search_keyword

st.title(f"ğŸ§¬ Global Research Trends: {keyword_display if keyword_display else '...'}")

if final_df is not None and not final_df.empty:
    
    # íƒ­ ë©”ë‰´
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“Š ë¹ˆë„ìˆ˜ íŠ¸ë Œë“œ", "ğŸ‘ï¸ ì¡°íšŒìˆ˜ íŠ¸ë Œë“œ", "ğŸ”— ìƒê´€ë¶„ì„", "ğŸ§‘â€ğŸ”¬ ì£¼ìš” ì—°êµ¬ì", "ğŸ“„ ë¦¬ìŠ¤íŠ¸"])

    # ë°ì´í„° ì „ì²˜ë¦¬
    all_titles = final_df['Title'].astype(str).tolist()
    if 'Views' not in final_df.columns:
        final_df['Views'] = 1
    
    final_df['Views'] = final_df['Views'].fillna(1).replace(0, 1)
    all_views = final_df['Views'].tolist()
    
    final_stop_words = set(st.session_state.user_excludes)
    if keyword_display:
        split_keywords = keyword_display.lower().split()
        final_stop_words.update(split_keywords)

    weighted_word_counts = defaultdict(int) 
    simple_word_counts = defaultdict(int)   

    for title, view_count in zip(all_titles, all_views):
        words_in_title = re.findall(r'\b[a-zA-Z]{3,}\b', title.lower())
        for w in words_in_title:
            if w not in final_stop_words:
                weighted_word_counts[w] += view_count 
                simple_word_counts[w] += 1            

    # === [Tab 1] ë‹¨ìˆœ ë¹ˆë„ìˆ˜ íŠ¸ë Œë“œ ===
    with tab1:
        st.markdown("### ğŸ“Š Basic Frequency WordCloud")
        st.caption("ì¡°íšŒìˆ˜ì™€ ìƒê´€ì—†ì´, ë…¼ë¬¸ ì œëª©ì— **ê°€ì¥ ë§ì´ ë“±ì¥í•œ í‚¤ì›Œë“œ**ì…ë‹ˆë‹¤.")

        if len(simple_word_counts) > 0:
            col1, col2 = st.columns([1.2, 1])
            with col1:
                wc_simple = WordCloud(width=800, height=500, background_color='white', colormap='viridis').generate_from_frequencies(simple_word_counts)
                fig_wc, ax = plt.subplots()
                ax.imshow(wc_simple, interpolation='bilinear')
                ax.axis('off')
                st.pyplot(fig_wc)

            with col2:
                st.markdown("#### ğŸ† Top Frequency Keywords")
                top_10_simple = sorted(simple_word_counts.items(), key=lambda x: x[1], reverse=True)[:10]
                
                if top_10_simple:
                    top_words = [item[0] for item in top_10_simple]
                    top_scores = [item[1] for item in top_10_simple]
                    
                    fig_bar, ax = plt.subplots(figsize=(5, 4))
                    ax.barh(top_words[::-1], top_scores[::-1], color='#4CAF50') 
                    ax.set_xlabel('Frequency (Count)')
                    st.pyplot(fig_bar)
        else:
            st.info("âš ï¸ ë¶„ì„í•  ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # === [Tab 2] ì¡°íšŒìˆ˜ ê¸°ë°˜ íŠ¸ë Œë“œ ===
    with tab2:
        st.markdown("### ğŸ‘ï¸ Impact WordCloud (Weighted by Views)")
        st.caption("ì‚¬ëŒë“¤ì´ **ì‹¤ì œë¡œ ë§ì´ ì¡°íšŒí•œ ë…¼ë¬¸**ì˜ í‚¤ì›Œë“œë¥¼ ë” í¬ê²Œ ë³´ì—¬ì¤ë‹ˆë‹¤.")
        
        if len(weighted_word_counts) > 0 and max(weighted_word_counts.values()) > 0:
            col1, col2 = st.columns([1.2, 1])
            with col1:
                try:
                    wc_weighted = WordCloud(width=800, height=500, background_color='white', colormap='magma').generate_from_frequencies(weighted_word_counts)
                    fig_wc, ax = plt.subplots()
                    ax.imshow(wc_weighted, interpolation='bilinear')
                    ax.axis('off')
                    st.pyplot(fig_wc)
                except Exception as e:
                    st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

            with col2:
                st.markdown("#### ğŸ† High Impact Keywords")
                top_10_weighted = sorted(weighted_word_counts.items(), key=lambda x: x[1], reverse=True)[:10]
                
                if top_10_weighted:
                    top_words = [item[0] for item in top_10_weighted]
                    top_scores = [item[1] for item in top_10_weighted]
                    
                    fig_bar, ax = plt.subplots(figsize=(5, 4))
                    ax.barh(top_words[::-1], top_scores[::-1], color='#e17055') 
                    ax.set_xlabel('Total Views')
                    st.pyplot(fig_bar)
        else:
            st.warning("âš ï¸ ì¡°íšŒìˆ˜ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ê°€ì¤‘ì¹˜ ë¶„ì„ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # === [Tab 3] ìƒê´€ê´€ê³„ ë¶„ì„ ===
    with tab3:
        st.markdown("#### ğŸ”— í‚¤ì›Œë“œ ë™ì‹œ ì¶œí˜„ ìƒê´€ê´€ê³„")
        if len(simple_word_counts) > 1:
            top_keywords = [item[0] for item in sorted(simple_word_counts.items(), key=lambda x: x[1], reverse=True)[:10]]
            
            matrix_data = []
            for title in final_df['Title'].astype(str):
                row = []
                title_lower = title.lower()
                for key in top_keywords:
                    row.append(1 if key in title_lower else 0)
                matrix_data.append(row)
            
            if matrix_data:
                df_matrix = pd.DataFrame(matrix_data, columns=top_keywords)
                corr_matrix = df_matrix.corr().fillna(0)
                
                fig_heat, ax = plt.subplots(figsize=(8, 6))
                sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='Blues', ax=ax)
                st.pyplot(fig_heat)
            else:
                st.info("ë°ì´í„° ë¶€ì¡±")
        else:
            st.warning("ë°ì´í„° ë¶€ì¡±")

    # === [Tab 4] ì£¼ìš” ì—°êµ¬ì ===
    with tab4:
        st.markdown(f"#### ğŸ§‘â€ğŸ”¬ Top Authors Analysis")
        
        author_freq_dict = defaultdict(int)
        author_view_dict = defaultdict(int)
        
        for authors_str, views in zip(final_df['Authors'].astype(str), final_df['Views']):
            authors_str = authors_str.replace("by ", "")
            cleaned = authors_str.replace(" and ", ", ").split(",")
            for name in cleaned:
                name = name.strip()
                if len(name) > 2: 
                    author_freq_dict[name] += 1
                    author_view_dict[name] += views
        
        auth_tab1, auth_tab2 = st.tabs(["ğŸ“š ë…¼ë¬¸ìˆ˜ ê¸°ì¤€ (Quantity)", "ğŸŒŸ ì˜í–¥ë ¥ ê¸°ì¤€ (Impact)"])
        
        with auth_tab1:
            if author_freq_dict:
                top_authors_freq = sorted(author_freq_dict.items(), key=lambda x: x[1], reverse=True)[:10]
                names = [item[0] for item in top_authors_freq]
                counts = [item[1] for item in top_authors_freq]
                
                fig_a1, ax = plt.subplots(figsize=(8, 4))
                ax.bar(names, counts, color='#ff7675') 
                plt.xticks(rotation=45, ha='right')
                ax.set_title("Most Prolific Authors")
                st.pyplot(fig_a1)
            else:
                st.warning("ì €ì ì •ë³´ ì—†ìŒ")
        
        with auth_tab2:
            if author_view_dict and max(author_view_dict.values()) > 0:
                top_authors_view = sorted(author_view_dict.items(), key=lambda x: x[1], reverse=True)[:10]
                names = [item[0] for item in top_authors_view]
                views = [item[1] for item in top_authors_view]
                
                fig_a2, ax = plt.subplots(figsize=(8, 4))
                ax.bar(names, views, color='#6c5ce7') 
                plt.xticks(rotation=45, ha='right')
                ax.set_title("Most Impactful Authors")
                st.pyplot(fig_a2)
            else:
                st.info("ì¡°íšŒìˆ˜ ë°ì´í„° ë¶€ì¡±")

    # === [Tab 5] ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ===
    with tab5:
        st.write(f"ì´ **{len(final_df)}**ê±´ì˜ ë…¼ë¬¸")
        
        final_df_display = final_df.copy()
        final_df_display.index = final_df_display.index + 1
        st.dataframe(final_df_display)

elif data_source == "ğŸŒ ì‹¤ì‹œê°„ ê²€ìƒ‰(Live)":
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ê³  ê²€ìƒ‰í•´ì£¼ì„¸ìš”.")
